{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L. Wi-Fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from collections import defaultdict\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates distance between 2 points\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "# computes how many ngrams string s1 ans s2 have in common\n",
    "def compare_ngrams(s1, s2, n):\n",
    "    ngrams1 = [s1[i:i + n] for i in range(len(s1) - n)]\n",
    "    ngrams2 = [s2[i:i + n] for i in range(len(s2) - n)]\n",
    "    count = 0\n",
    "    for ngram1 in ngrams1:\n",
    "        for ngram2 in ngrams2:\n",
    "            if ngram1 == ngram2:\n",
    "                count += 1\n",
    "    return count / max(len(s1), len(s2))\n",
    "\n",
    "def compute_score(y_hat, y_true):\n",
    "    groups = df.iloc[train_idx].group_num if y_true.params['train'] else df.iloc[test_idx].group_num\n",
    "    groups = groups.values\n",
    "    targets = y_true.get_label().values\n",
    "    max_pred = defaultdict(lambda: (-1, -1))\n",
    "    n = len(y_hat)\n",
    "    for i in range(n):\n",
    "        if max_pred[groups[i]][0] < y_hat[i]:\n",
    "            max_pred[groups[i]] = (y_hat[i], i)\n",
    "    acc = 0\n",
    "    for _, i in max_pred.values():\n",
    "        acc += targets[i]\n",
    "    acc /= len(max_pred)\n",
    "    return 'score', 1 + 6 * (acc - 0.5), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>candidate_num</th>\n",
       "      <th>group_num</th>\n",
       "      <th>has_wifi</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>names</th>\n",
       "      <th>publishing_status</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>ssid</th>\n",
       "      <th>target</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_lat</th>\n",
       "      <th>user_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия, Новосибирская область, Обь, проспект М...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.007759</td>\n",
       "      <td>82.667023</td>\n",
       "      <td>[\"Сбербанк России, банкомат\", \"Sberbank Rossii...</td>\n",
       "      <td>publish</td>\n",
       "      <td>[30336]</td>\n",
       "      <td>Tolmachevo-MTS-Free</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"type\": \"main\", \"value\": \"http://www.sberban...</td>\n",
       "      <td>55.007579</td>\n",
       "      <td>82.666723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Россия, Новосибирская область, аэропорт Новоси...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.007879</td>\n",
       "      <td>82.665401</td>\n",
       "      <td>[\"Ил-86\"]</td>\n",
       "      <td>publish</td>\n",
       "      <td>[3481524327]</td>\n",
       "      <td>Tolmachevo-MTS-Free</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>55.007579</td>\n",
       "      <td>82.666723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Россия, Новосибирская область, Обь, проспект М...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.007570</td>\n",
       "      <td>82.667069</td>\n",
       "      <td>[\"Чашка кофе\", \"Чашка Кофе\"]</td>\n",
       "      <td>publish</td>\n",
       "      <td>[31495]</td>\n",
       "      <td>Tolmachevo-MTS-Free</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"type\": \"mining\", \"value\": \"https://2gis.ru/...</td>\n",
       "      <td>55.007579</td>\n",
       "      <td>82.666723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Россия, Новосибирская область, Обь, проспект М...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>55.007337</td>\n",
       "      <td>82.667066</td>\n",
       "      <td>[\"Чашка кофе\", \"Chashka kofe\", \"Чашка кофе\", \"...</td>\n",
       "      <td>publish</td>\n",
       "      <td>[31495]</td>\n",
       "      <td>Tolmachevo-MTS-Free</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"type\": \"main\", \"value\": \"http://chashkacoff...</td>\n",
       "      <td>55.007579</td>\n",
       "      <td>82.666723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Россия, Новосибирская область, Обь, проспект М...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.007623</td>\n",
       "      <td>82.666341</td>\n",
       "      <td>[\"Телефон доверия\"]</td>\n",
       "      <td>obsolete</td>\n",
       "      <td>[30078]</td>\n",
       "      <td>Tolmachevo-MTS-Free</td>\n",
       "      <td>0</td>\n",
       "      <td>[{\"type\": \"mining\", \"value\": \"https://2gis.ru/...</td>\n",
       "      <td>55.007579</td>\n",
       "      <td>82.666723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address  candidate_num  \\\n",
       "0  Россия, Новосибирская область, Обь, проспект М...              0   \n",
       "1  Россия, Новосибирская область, аэропорт Новоси...              1   \n",
       "2  Россия, Новосибирская область, Обь, проспект М...              2   \n",
       "3  Россия, Новосибирская область, Обь, проспект М...              3   \n",
       "4  Россия, Новосибирская область, Обь, проспект М...              4   \n",
       "\n",
       "   group_num has_wifi        lat        lon  \\\n",
       "0          0      NaN  55.007759  82.667023   \n",
       "1          0      NaN  55.007879  82.665401   \n",
       "2          0      NaN  55.007570  82.667069   \n",
       "3          0     True  55.007337  82.667066   \n",
       "4          0      NaN  55.007623  82.666341   \n",
       "\n",
       "                                               names publishing_status  \\\n",
       "0  [\"Сбербанк России, банкомат\", \"Sberbank Rossii...           publish   \n",
       "1                                          [\"Ил-86\"]           publish   \n",
       "2                       [\"Чашка кофе\", \"Чашка Кофе\"]           publish   \n",
       "3  [\"Чашка кофе\", \"Chashka kofe\", \"Чашка кофе\", \"...           publish   \n",
       "4                                [\"Телефон доверия\"]          obsolete   \n",
       "\n",
       "        rubrics                 ssid  target  \\\n",
       "0       [30336]  Tolmachevo-MTS-Free       0   \n",
       "1  [3481524327]  Tolmachevo-MTS-Free       0   \n",
       "2       [31495]  Tolmachevo-MTS-Free       0   \n",
       "3       [31495]  Tolmachevo-MTS-Free       0   \n",
       "4       [30078]  Tolmachevo-MTS-Free       0   \n",
       "\n",
       "                                                urls   user_lat   user_lon  \n",
       "0  [{\"type\": \"main\", \"value\": \"http://www.sberban...  55.007579  82.666723  \n",
       "1                                                 []  55.007579  82.666723  \n",
       "2  [{\"type\": \"mining\", \"value\": \"https://2gis.ru/...  55.007579  82.666723  \n",
       "3  [{\"type\": \"main\", \"value\": \"http://chashkacoff...  55.007579  82.666723  \n",
       "4  [{\"type\": \"mining\", \"value\": \"https://2gis.ru/...  55.007579  82.666723  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('input/l_train.tsv', sep='\\t', index_col=0)\n",
    "df_test = pd.read_csv('input/l_test.tsv', sep='\\t', index_col=0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter rows with **target==1** and look at **ssid** and **names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>ssid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[\"Аэропорт Толмачево, бухгалтерия\", \"Толмачево\"]</td>\n",
       "      <td>Tolmachevo-MTS-Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[\"Kontrolmatik\"]</td>\n",
       "      <td>Kontrolmatik_Staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[\"ПКВ Моторс\", \"Pkw Motors\", \"Pkw Motors\", \"Те...</td>\n",
       "      <td>PKW Guests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[\"Техцентр Юста\", \"Tekhtsentr Yusta\", \"Юста\", ...</td>\n",
       "      <td>YUSTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[\"Респект Авто\", \"Автосервис\"]</td>\n",
       "      <td>RespectAuto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                names                 ssid\n",
       "18   [\"Аэропорт Толмачево, бухгалтерия\", \"Толмачево\"]  Tolmachevo-MTS-Free\n",
       "38                                   [\"Kontrolmatik\"]   Kontrolmatik_Staff\n",
       "49  [\"ПКВ Моторс\", \"Pkw Motors\", \"Pkw Motors\", \"Те...           PKW Guests\n",
       "77  [\"Техцентр Юста\", \"Tekhtsentr Yusta\", \"Юста\", ...                YUSTA\n",
       "94                     [\"Респект Авто\", \"Автосервис\"]          RespectAuto"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.target == 1][['names', 'ssid']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice, that almost always they have a lot in common. Though sometimes they are written in different\n",
    "languages/cases. A simple heuristic to meausure how much strings have in common would be to transliterate\n",
    "cyrillyc and accented letters and to calculate how many char ngrams they have in common for different **n**. I used **n=1..8**. That are very strong features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute features. It might take up to 7 minutes and several GB of RAM. The longset part is one-hot encoding rubrics and calculating number of matching ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109016, 1210)\n",
      "CPU times: user 6min 24s, sys: 27.3 s, total: 6min 51s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.concat((df_train, df_test))\n",
    "df['test'] = df.target.isnull()\n",
    "df['publishing_status'] = df['publishing_status'].astype('category')\n",
    "df['has_wifi'] = df['has_wifi'].astype(float)\n",
    "df['distance_km'] = haversine_np(df.lon, df.lat, df.user_lon, df.user_lat)\n",
    "df['distance_lat'] = df.user_lat - df.lat\n",
    "df['distance_lon'] = df.user_lon - df.lon\n",
    "df['abs_distance_lat'] = abs(df.user_lat - df.lat)\n",
    "df['abs_distance_lon'] = abs(df.user_lon - df.lon)\n",
    "df = pd.concat((df, df.rubrics.str.replace('[\\[\\]\\s]', '').str.get_dummies(',').add_prefix('rubric_')), axis=1)\n",
    "for i in range(1, 9):\n",
    "    df[f'ngrams_match_names_{i}'] = df.apply(lambda x: compare_ngrams(unidecode(x.names.lower()), unidecode(x.ssid.lower()), i), axis=1)\n",
    "    df[f'ngrams_match_urls_{i}'] = df.apply(lambda x: compare_ngrams(unidecode(x.urls.lower()), unidecode(x.ssid.lower()), i), axis=1)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should use group-aware validation, so I used `GroupShuffleSplit` which will place all samples from one group\n",
    "to either train or test set, so that test and train sets will have non-intersecting groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['lon', 'lat', 'has_wifi', 'user_lon', 'user_lat', 'publishing_status', 'distance_km',\n",
    "          'distance_lat', 'distance_lon', 'abs_distance_lat', 'abs_distance_lon'] + \\\n",
    "          [c for c in df.columns if c.startswith('rubric_')] + \\\n",
    "          [c for c in df.columns if c.startswith('ngrams_match_')]\n",
    "train_idx, test_idx = next(GroupShuffleSplit(1, test_size=0.20, random_state=2)\n",
    "                           .split(df[~df.test].index, groups=df[~df.test].group_num))\n",
    "train_ds = lgb.Dataset(df.iloc[train_idx][columns],\n",
    "                       df.iloc[train_idx].target, params={'train': 1})\n",
    "valid_ds = lgb.Dataset(df.iloc[test_idx][columns],\n",
    "                       df.iloc[test_idx].target, params={'train': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.110857\ttraining's score: 3.54714\tvalid_1's binary_logloss: 0.112376\tvalid_1's score: 3.48571\n",
      "[40]\ttraining's binary_logloss: 0.0525294\ttraining's score: 3.63571\tvalid_1's binary_logloss: 0.0575634\tvalid_1's score: 3.54286\n",
      "[60]\ttraining's binary_logloss: 0.0402884\ttraining's score: 3.72714\tvalid_1's binary_logloss: 0.0493212\tvalid_1's score: 3.58286\n",
      "[80]\ttraining's binary_logloss: 0.0344945\ttraining's score: 3.77429\tvalid_1's binary_logloss: 0.0472072\tvalid_1's score: 3.58286\n",
      "[100]\ttraining's binary_logloss: 0.0304829\ttraining's score: 3.82571\tvalid_1's binary_logloss: 0.0463274\tvalid_1's score: 3.59429\n",
      "[120]\ttraining's binary_logloss: 0.0276586\ttraining's score: 3.85429\tvalid_1's binary_logloss: 0.0456935\tvalid_1's score: 3.6\n",
      "[140]\ttraining's binary_logloss: 0.0251468\ttraining's score: 3.89\tvalid_1's binary_logloss: 0.0454254\tvalid_1's score: 3.61714\n",
      "[160]\ttraining's binary_logloss: 0.0228951\ttraining's score: 3.90714\tvalid_1's binary_logloss: 0.0452949\tvalid_1's score: 3.58857\n",
      "[180]\ttraining's binary_logloss: 0.0211293\ttraining's score: 3.92571\tvalid_1's binary_logloss: 0.0452031\tvalid_1's score: 3.57143\n",
      "[200]\ttraining's binary_logloss: 0.0195177\ttraining's score: 3.94143\tvalid_1's binary_logloss: 0.0450583\tvalid_1's score: 3.55429\n",
      "[220]\ttraining's binary_logloss: 0.0180155\ttraining's score: 3.95571\tvalid_1's binary_logloss: 0.0451257\tvalid_1's score: 3.57143\n",
      "[240]\ttraining's binary_logloss: 0.016726\ttraining's score: 3.96857\tvalid_1's binary_logloss: 0.0450745\tvalid_1's score: 3.54286\n",
      "[260]\ttraining's binary_logloss: 0.0154913\ttraining's score: 3.98\tvalid_1's binary_logloss: 0.0451456\tvalid_1's score: 3.55429\n",
      "[280]\ttraining's binary_logloss: 0.0143795\ttraining's score: 3.98571\tvalid_1's binary_logloss: 0.0452139\tvalid_1's score: 3.58286\n",
      "[300]\ttraining's binary_logloss: 0.0134922\ttraining's score: 3.98571\tvalid_1's binary_logloss: 0.0452774\tvalid_1's score: 3.57714\n"
     ]
    }
   ],
   "source": [
    "params = { 'objective': 'binary' }\n",
    "model = lgb.train(params, train_ds, valid_sets=[train_ds, valid_ds], verbose_eval=20, num_boost_round=300, feval=compute_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we see that validation score stops increasing quite soon after **140** iterations reaching **3.61** out of 4 which is not so bad 😎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we know how much rounds we need, we can feed the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(df[~df.test][columns], df[~df.test].target, params={'train': 1})\n",
    "params = { 'objective': 'binary' }\n",
    "train_idx = df[~df.test].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's binary_logloss: 0.232019\ttraining's score: 3.43657\n",
      "[20]\ttraining's binary_logloss: 0.111026\ttraining's score: 3.54971\n",
      "[30]\ttraining's binary_logloss: 0.0690424\ttraining's score: 3.61486\n",
      "[40]\ttraining's binary_logloss: 0.0528524\ttraining's score: 3.64114\n",
      "[50]\ttraining's binary_logloss: 0.0454717\ttraining's score: 3.67543\n",
      "[60]\ttraining's binary_logloss: 0.0413087\ttraining's score: 3.70514\n",
      "[70]\ttraining's binary_logloss: 0.0382407\ttraining's score: 3.73829\n",
      "[80]\ttraining's binary_logloss: 0.036007\ttraining's score: 3.74857\n",
      "[90]\ttraining's binary_logloss: 0.0341142\ttraining's score: 3.77143\n",
      "[100]\ttraining's binary_logloss: 0.0324071\ttraining's score: 3.79543\n",
      "[110]\ttraining's binary_logloss: 0.0310263\ttraining's score: 3.80686\n",
      "[120]\ttraining's binary_logloss: 0.0297982\ttraining's score: 3.824\n",
      "[130]\ttraining's binary_logloss: 0.0286451\ttraining's score: 3.83657\n",
      "[140]\ttraining's binary_logloss: 0.0276137\ttraining's score: 3.84343\n",
      "[150]\ttraining's binary_logloss: 0.0266454\ttraining's score: 3.85943\n",
      "[160]\ttraining's binary_logloss: 0.0256527\ttraining's score: 3.87086\n",
      "[170]\ttraining's binary_logloss: 0.0247839\ttraining's score: 3.88229\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params, train_ds, valid_sets=train_ds, verbose_eval=10, num_boost_round=170, feval=compute_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict, save and submit! 🎉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(df[df.test][columns])\n",
    "predictions = pd.concat((df[df.test], pd.Series(predictions, name='pred')), axis=1)[['group_num', 'pred']]\n",
    "predictions['target'] = 0\n",
    "predictions.loc[predictions[['group_num', 'pred']].groupby('group_num').idxmax().values[:, 0], 'target'] = 1\n",
    "predictions.target.to_csv('output/l.out', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
